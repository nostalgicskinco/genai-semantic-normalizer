# AWS Bedrock attribute mappings
# Sources: boto3 bedrock-runtime, OpenLLMetry AWS instrumentation
# Last verified: 2024-12

vendor: aws
framework: bedrock
description: >
  Mappings for AWS Bedrock API calls. Bedrock wraps multiple model
  providers (Anthropic, Meta, Cohere, etc.) behind a unified API.
  When instrumented via OpenLLMetry, attributes follow the llm.*
  namespace with bedrock-specific additions.

mappings:
  # Model
  llm.request.model: gen_ai.request.model
  llm.response.model: gen_ai.response.model
  llm.model: gen_ai.request.model
  model: gen_ai.request.model

  # Provider (will typically be "bedrock" or the underlying provider)
  llm.vendor: gen_ai.system
  llm.provider: gen_ai.system

  # Token usage
  llm.usage.prompt_tokens: gen_ai.usage.input_tokens
  llm.usage.completion_tokens: gen_ai.usage.output_tokens
  llm.usage.total_tokens: gen_ai.usage.total_tokens
  input_tokens: gen_ai.usage.input_tokens
  output_tokens: gen_ai.usage.output_tokens
  prompt_tokens: gen_ai.usage.input_tokens
  completion_tokens: gen_ai.usage.output_tokens

  # Request parameters
  llm.request.temperature: gen_ai.request.temperature
  llm.request.max_tokens: gen_ai.request.max_tokens
  llm.request.top_p: gen_ai.request.top_p
  llm.temperature: gen_ai.request.temperature
  max_tokens: gen_ai.request.max_tokens

  # Response
  llm.response.finish_reason: gen_ai.response.finish_reasons
  finish_reason: gen_ai.response.finish_reasons

  # Content
  llm.prompt: gen_ai.prompt
  llm.completion: gen_ai.completion

  # Cost
  llm.usage.cost: gen_ai.usage.cost

# Known span names emitted:
#   - bedrock.invoke_model
#   - bedrock.invoke_model_with_response_stream
#   - bedrock.converse
